# Project Overview
Our project is divided into two main parts: **generating double exposure images** and **evaluating the quality of those images**.


##  Double Exposure Image Generation

We explore three different methods for generating double exposure images:

- **Traditional Image Processing**  
  [`Traditional Operation/Pipeline(Tradition).ipynb`](Traditional%20Operation/Pipeline(Tradition).ipynb)

- **ControlNet-based Generation**  
  [`ControlNet/ControlNet_Pipeline_HedTest.ipynb`](ControlNet/ControlNet_Pipeline_HedTest.ipynb)

- **Stable Diffusion with Latent Blending**  
  [`latent_blending/SD_blending_latents.ipynb`](latent_blending/SD_blending_latents.ipynb)

---

## Double Exposure Image Evaluation

We evaluate the generated images using three different approaches:

- **CLIP-based Semantic Similarity**  
  [`clip_evaluation/clip_evaluation.ipynb`](clip_evaluation/clip_evaluation.ipynb)

- **NIMA-based Aesthetic Scoring**  
  [`NIMA_evaluation/NIMA.ipynb`](NIMA_evaluation/NIMA.ipynb)

- **Our Proposed Metric Based on Empty Space Completeness**  
  [`new_metric/1_Silhouette_Completeness_Score.ipynb`](new_metric/1_Silhouette_Completeness_Score.ipynb)

To evaluate whether our proposed metric accurately reflects human aesthetic preferences, we conducted a survey among our classmates.  
The survey can be accessed [here](https://docs.google.com/forms/d/1JZuLU_eVU8ESYaRmBidF4uqUxly6MGZ4_WRVSDD8B1c).

# Project Structure
<pre><code>
.  
├── README.md  
│  
├── clip_evaluation  
│   ├── clip_evaluation.ipynb # Code for CLIP evaluation
│   └── imgs/  # The output of evaluation results
│  
├── ControlNet  
│   ├── ControlNet_Pipeline_HedTest.ipynb  # Code for Hed ControlNet to generate double exposure image
│   ├── Hed Image/  # The HED Image of the Source Image
│   └── Source Image/  # The Source Image to Generate Double Exposure Image
│  
├── dataset  
│   ├── controlnet/  # The image generated by controlnet for evaluation
│   ├── latent_blending/  # The image generated by stable diffusion for evaluation
│   └── real_photos/  # The image we search from the internet
│  
├── Human Evaluation  
│   ├── original_results.csv  # The original results download from google form which contains the answer of open question
│   └── statistic_results.csv  # The cleanup results only for statistic analysis
│  
├── latent_blending  
│   └── SD_blending_latents.ipynb  # Code for stable  to Generate Double Exposure Image
│  
├── new_metric  
│   ├── 1_Silhouette_Completeness_Score.ipynb  # Code for our own evaluation metric
│   ├── 2_Results_Analysis_Real_IMG.ipynb  # Code for evaluate which evaluation metric aligns better with human annotations
│   ├── data/  
│   │   ├── aesthetic_scores_from_new.csv  # The evaluation results for our own metric
│   │   ├── ranking.txt  # ranking list of evaluation metric
│   │   └── ranking_evaluation.csv  # ranking list of evaluation metric and its original scores
│   └── imgs/  
│ 
├── NIMA_evaluation
│   └── NIMA.ipynb # Code for NIMA evaluation
│  
└── Traditional Operation  
    └── Pipeline(Tradition).ipynb  # Code for using traditional operations to generate double exposure images

  
  </code></pre>
